# CellEmbedâ€‘SAM: Multimodal Cell/Nuclei Instance Segmentation

> A complete pipeline for multimodal microscopic **cell or nuclei instance segmentation** built on the **CellEmbedâ€‘SAM** family of models.  
> Includes dataset preparation, training, evaluation, batch inference, and a lightweight GUI.

<p align="center">
  <img src="docs/teaser.png" alt="CEmbed-SAM teaser (placeholder)" width="80%"/>
</p>

## âœ¨ Highlights
- **Generalizable** across modalities (fluorescence, brightfield, H&E/IHC, bacteria, etc.).
- **Plugâ€‘andâ€‘play backbones:** `CellEmbed`, `InstanSeg`, `CellPose-SAM`, `CellPose3`, `MicroSAM`, `CellViT`, `Mediar`.
- **Practical utilities:** data loaders, augmentation, postâ€‘processing, evaluation, and **GUI**.
- **Pretrained weights:** download checkpoints for CEmbedâ€‘SAM and 6+ baselines from  
  <http://www.oncoimmunobank.cn/software/item/CellEmbed>.

---

## ğŸ—‚ Repository Structure
```text
CellEmbed-main/
â”œâ”€â”€ cellembed/                      # Main framework
â”‚   â”œâ”€â”€ pretrained CEmbed-SAM/
â”‚   â”‚   â””â”€â”€ CEmbed_SAM/
â”‚   â”‚       â””â”€â”€ model_weights.pth   # Trained CEmbed-SAM checkpoint (used by GUI)
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train.py                # Training entry
â”‚   â”‚   â””â”€â”€ test.py                 # Evaluation entry
â”‚   â”œâ”€â”€ datasets/                   # .pth datasets (generated by raw_datasets/load_datasets.py)
â”‚   â”œâ”€â”€ All_train/                  # Weights & logs for multimodality experiments
â”‚   â”‚   â”œâ”€â”€ CEmbed SAM/             # each: model_weights.pth + experiment_log.csv
â”‚   â”‚   â”œâ”€â”€ CellPose SAM/
â”‚   â”‚   â”œâ”€â”€ Micro SAM/
â”‚   â”‚   â”œâ”€â”€ CellPose3/
â”‚   â”‚   â”œâ”€â”€ CellViT/
â”‚   â”‚   â”œâ”€â”€ Instanseg/
â”‚   â”‚   â””â”€â”€ Mediar/
â”‚   â”œâ”€â”€ TNBC_2018/                  # Dataset-specific training results
â”‚   â”‚   â”œâ”€â”€ CEmbed SAM/
â”‚   â”‚   â”œâ”€â”€ CellPose SAM/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...                         # Core models, losses, utils
â”‚
â”œâ”€â”€ inference/                      # Batch inference utilities
â”‚   â””â”€â”€ inference.py                # Inference on arbitrary PNG/JPG folders
â”‚
â”œâ”€â”€ othermodel/                     # Baseline/alternative frameworks
â”‚   â”œâ”€â”€ cellposesam/                # CellPose-SAM
â”‚   â”œâ”€â”€ cellpose/                   # CellPose3
â”‚   â”œâ”€â”€ cellvit/                    # CellViT
â”‚   â”œâ”€â”€ mediar/                     # MediarFormer
â”‚   â””â”€â”€ microsam/                   # Micro-SAM
â”‚
â”œâ”€â”€ raw_datasets/                   # Raw dataset loaders/adapters
â”‚   â””â”€â”€ load_datasets.py            # Converts raw image folders into .pth datasets
â”‚
â”œâ”€â”€ segmentation_anything/          # SAM backbone dependencies
â”œâ”€â”€ gui/                            # Simple GUI for cell segmentation
â”‚   â””â”€â”€ segment_gui.py              # Loads CEmbed-SAM weights
â”œâ”€â”€ sam_vit_l.pth                   # Pretrained SAM ViT-L weights
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Installation
```bash
git clone https://github.com/zhangjbig/CellEmbed-SAM.git
cd cellembed-sam
pip install -r requirements.txt
```

> **Note:** Python â‰¥3.9 and PyTorch with CUDA are recommended.

---

## ğŸ“¦ Dataset Preparation
Use the converter to turn raw `Slide_*/GT_*` pairs into a `.pth` dataset.

```bash
python -m raw_datasets.load_datasets \
  --input_root raw_datasets/TNBC_NucleiSegmentation/TNBC_and_Brain_dataset \
  --output_dir cellembed/datasets
```

**Expected raw layout**
```text
raw_datasets/TNBC_NucleiSegmentation/
â””â”€â”€ TNBC_and_Brain_dataset/
    â”œâ”€â”€ Slide_001/
    â”‚   â”œâ”€â”€ img1.png
    â”‚   â”œâ”€â”€ img2.png
    â”‚   â””â”€â”€ ...
    â””â”€â”€ GT_001/
        â”œâ”€â”€ img1.png
        â”œâ”€â”€ img2.png
        â””â”€â”€ ...
```

**Resulting `.pth` files**
```text
cellembed/datasets/
â”œâ”€â”€ TNBC_2018.pth
â”œâ”€â”€ CoNSeP.pth
â”œâ”€â”€ IHC_TMA.pth
â””â”€â”€ LyNSeC.pth
```

---

## ğŸ”§ Training
```bash
python -m cellembed.scripts.train \
  --data_path "cellembed/datasets" \
  --dataset "TNBC_2018" \
  --model_str "cellembed" \
  --output_path "cellembed/TNBC_2018" \
  --experiment_str "CEmbed SAM" \
  --num_epochs 200 \
  --length_of_epoch 10 \
  --batch_size 1 \
  --num_workers 2 \
  --optimizer "adamw" \
  --device "cuda:0"
```

### Key Arguments
| Argument | Description |
|---|---|
| `--data_path` | Path to folder with `.pth` datasets |
| `--dataset` | Dataset name (e.g., `TNBC_2018`) |
| `--model_str` | Backbone (`cellembed`, `instanseg_unet`, `cellposesam`, `cellpose3`, `microsam`, `cellvit`, `mediar`) |
| `--optimizer` | Optimizer (`adam`, `sgd`, `adamw`) |
| `--length_of_epoch` | #samples per epoch |
| `--num_epochs` | #epochs |
| `--batch_size` | Batch size |
| `--lr` | Learning rate |
| `--output_path` | Root dir to save weights/logs for this dataset |
| `--experiment_str` | Run folder name under `--output_path` |

> **Evaluation config** (used by `test.py`):  
> `--model_path` should point to the same directory as training `--output_path`, and `--model_folder` to the same string as training `--experiment_str`.

---

## ğŸ“ˆ Evaluation
```bash
python -m cellembed.scripts.test \
  --data_path "cellembed/datasets" \
  --dataset "TNBC_2018" \
  --model_path "cellembed/TNBC_2018" \
  --model_folder "CEmbed SAM" \
  --output_folder "Results" \
  --test_set "Validation" \
  --save_ims True
```

---

## ğŸ–¼ Inference
### GUI (Interactive)
```bash
# Option 1
python -m gui.segment_gui

```

---

## ğŸ“¤ Outputs
- **Checkpoints:** `model_weights.pth`  
- **Logs:** `experiment_log.csv`, `experiment_metrics.csv`  
- **Plots:** `loss.png` (train/val loss), `f1_metric.png` (F1 trajectory)

---

## ğŸ“œ License
This project is released under the **MIT License** (see `LICENSE`).

---

## ğŸ™ Acknowledgements
- The SAM backbone and related components build on open-source efforts from the community.
- Baselines included: **CellPoseâ€‘SAM**, **CellPose3**, **MicroSAM**, **CellViT**, **Mediar**, **InstanSeg**.
- We thank contributors for datasets and evaluation tools.
